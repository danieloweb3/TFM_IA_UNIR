{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEMorkUQqRFK"
      },
      "source": [
        "# Carga y análisis del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v31cGuq4LTyf"
      },
      "source": [
        "Instalar librerías necesarias (si no están instaladas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtyEB6awnhMg"
      },
      "outputs": [],
      "source": [
        "!pip install pandas openpyxl matplotlib seaborn --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install numpy==1.26.4 --quiet # (versión anterior)\n",
        "\n",
        "# Después de ejecutar estos comandos es necesario reiniciar el kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy-2w2cNLbAe"
      },
      "source": [
        "Importar librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wuw1WylvnkVr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpqlA2f2Liz3"
      },
      "source": [
        "Carga del dataset y normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14Nmc6yPnoQr"
      },
      "outputs": [],
      "source": [
        "ruta = \"/content/Dataset_Completo.xlsx\"\n",
        "df = pd.read_excel(ruta)\n",
        "\n",
        "# Limpieza y normalización de la columna 'Category'\n",
        "df['Category'] = df['Category'].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Mapeo de etiquetas: 'true' → 0 y 'fake' → 1\n",
        "df['label'] = df['Category'].map({'true': 0, 'fake': 1})\n",
        "\n",
        "# Verificación\n",
        "print(\"Valores únicos en 'Category':\", df['Category'].unique())\n",
        "print(\"Valores únicos en 'label':\", df['label'].unique())\n",
        "print(\"\\nDistribución de clases:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribución de clases"
      ],
      "metadata": {
        "id": "PoRAEZ-PfcTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df, x='label')\n",
        "plt.title(\"Distribución de clases (0 = verdadera, 1 = falsa)\")\n",
        "plt.xlabel(\"Etiqueta\")\n",
        "plt.ylabel(\"Número de ejemplos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6bFaWmWQfB8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos a texto y calculamos la longitud"
      ],
      "metadata": {
        "id": "nPve3OrvfFiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = df['Text'].astype(str).apply(len)\n",
        "print(\"\\nLongitud media de los textos:\", df['text_len'].mean())"
      ],
      "metadata": {
        "id": "kTFMom16fB_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico distribución de la longitud de los textos"
      ],
      "metadata": {
        "id": "HKnPK89pfgfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['text_len'], bins=40, kde=True)\n",
        "plt.title(\"Distribución de la longitud de los textos\")\n",
        "plt.xlabel(\"Número de caracteres\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFGUF2fFfB6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar primeros registros del dataset"
      ],
      "metadata": {
        "id": "I_VzxflAMsat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los primeros registros del dataset\n",
        "print(\"\\nPrimeros registros del dataset:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IfZyu8-RMq--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos nulos y datos faltantes"
      ],
      "metadata": {
        "id": "QossfHVTMaGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar si existen registros con al menos un campo en blanco o nulo\n",
        "registros_con_faltantes = df[df.isnull().any(axis=1)]\n",
        "total_con_faltantes = registros_con_faltantes.shape[0]\n",
        "\n",
        "# Mostrar resultado general\n",
        "print(f\"¿Existen registros con datos faltantes?: {total_con_faltantes > 0}\")\n",
        "print(f\"Total de registros con al menos un campo en blanco: {total_con_faltantes}\\n\")\n",
        "\n",
        "# Mostrar el número de valores nulos por columna\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "IV1m5_R2fBsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar los primeros registros con campos faltantes\n",
        "if total_con_faltantes > 0:\n",
        "    print(\"\\nPrimeros registros con campos faltantes:\")\n",
        "    print(registros_con_faltantes.head())"
      ],
      "metadata": {
        "id": "6J0zC0XnN8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCo-2vGeL9sv"
      },
      "source": [
        "# Entrenamiento de BETO con el texto completo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Usamos 'text', 'topic', 'source' y 'headline' como entrada. El campo LINK no lo utilizamos para el entrenamiento\n",
        "df_texto = df[['Text', 'Topic', 'Source', 'Headline', 'label']].dropna().copy()\n",
        "\n",
        "# Renombramos todas las columnas\n",
        "df_texto.rename(columns={\n",
        "    'Text': 'text',\n",
        "    'Topic': 'topic',\n",
        "    'Source': 'source',\n",
        "    'Headline': 'headline'\n",
        "}, inplace=True)\n",
        "\n",
        "# 2. División del dataset en entrenamiento y prueba\n",
        "train_df, test_df = train_test_split(df_texto, test_size=0.2, stratify=df_texto['label'], random_state=42)\n",
        "\n",
        "# 3. Conversión a datasets de Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# 4. Tokenizador y tokenización\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# 5. Formateo\n",
        "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# 6. Modelo BETO\n",
        "model = BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=2)\n",
        "\n",
        "# 7. Configuración de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_texto_completo\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    eval_strategy=\"epoch\",  # Para evaluar cada época\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 8 Preparación metricas entrenamiento\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# 9. Entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],  # Espera 2 épocas sin mejorar\n",
        ")\n",
        "\n",
        "# 10. Entrenar el modelo\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "G8cal9IfgDsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo entrenado con textos (lo usaremos con LIME)."
      ],
      "metadata": {
        "id": "QzWlJm0woTB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar modelo y tokenizer tras el entrenamiento\n",
        "trainer.save_model(\"./modelo_beto_fake_news\")\n",
        "tokenizer.save_pretrained(\"./modelo_beto_fake_news\")"
      ],
      "metadata": {
        "id": "vAwvbXAqoOjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación del modelo con texto completo"
      ],
      "metadata": {
        "id": "CR7-ETCKgdaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "# 1. Obtener predicciones\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# 2. Métricas principales\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "precision = precision_score(labels, preds)\n",
        "recall = recall_score(labels, preds)\n",
        "f1 = f1_score(labels, preds)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# 3. Reporte completo por clase\n",
        "print(\"\\nReporte completo:\")\n",
        "print(classification_report(labels, preds, target_names=[\"True\", \"Fake\"]))\n",
        "\n",
        "# 4. Matriz de confusión\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"True\", \"Fake\"], yticklabels=[\"True\", \"Fake\"])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión - Texto completo (BETO)')\n",
        "plt.show()\n",
        "\n",
        "# 5. Curva ROC y AUC\n",
        "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "auc = roc_auc_score(labels, probs)\n",
        "fpr, tpr, _ = roc_curve(labels, probs)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Clasificador aleatorio')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('Curva ROC - Modelo con texto completo (BETO)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OouagLS1gDoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Qyt9CJQLM-Im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretabilidad con LIME"
      ],
      "metadata": {
        "id": "ceLPCWBDvXdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar LIME"
      ],
      "metadata": {
        "id": "JSM04IWqvc3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime --quiet"
      ],
      "metadata": {
        "id": "QSZUuz1TvU56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./modelo_beto_fake_news\",\n",
        "    tokenizer=\"./modelo_beto_fake_news\",\n",
        "    return_all_scores=True\n",
        ")"
      ],
      "metadata": {
        "id": "EdqCIQHNX-za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importaciones y función predictiva"
      ],
      "metadata": {
        "id": "XxbeTpqOvjbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Definimos los nombres de las clases\n",
        "class_names = ['True', 'Fake']\n",
        "\n",
        "# Función para LIME: devuelve solo las probabilidades de clase\n",
        "def predict_lime(texts):\n",
        "    outputs = pipe(texts)\n",
        "    return np.array([[s['score'] for s in o] for o in outputs])"
      ],
      "metadata": {
        "id": "gxU969whvU3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializar el explicador y elegir un texto"
      ],
      "metadata": {
        "id": "mQ5rnlBuvq7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = LimeTextExplainer(class_names=class_names, random_state=42)\n",
        "\n",
        "# Seleccionamos un texto del dataset\n",
        "texto_ejemplo = df['Text'].dropna().astype(str).iloc[0][:1000]  # truncado por seguridad"
      ],
      "metadata": {
        "id": "17v2SWS7vU1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar la explicación y visualizarla"
      ],
      "metadata": {
        "id": "oeQeEGCPvtZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(texto_ejemplo, predict_lime, num_features=10)\n",
        "\n",
        "# Mostrar en notebook\n",
        "exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "Kn3I6n1KvUzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la explicación LIME como archivo HTML"
      ],
      "metadata": {
        "id": "eCgcbYQYwoBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar la explicación como archivo HTML\n",
        "exp.save_to_file('lime_explicacion_BETO.html')"
      ],
      "metadata": {
        "id": "w-KPAiUsvUxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WO8y-IeRNUdr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjZKGmnywVP5"
      },
      "source": [
        "# Interpretabilidad con SHAP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque las explicaciones SHAP se generan sobre un modelo base multilingüe, la interpretación general puede extrapolarse razonablemente al comportamiento del modelo fine-tuned entrenado en este trabajo, ya que ambos comparten la misma arquitectura."
      ],
      "metadata": {
        "id": "K-MhN4Xqzptn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar librerías necesarias"
      ],
      "metadata": {
        "id": "Djmvjn_wx7rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap scikit-learn nltk --quiet"
      ],
      "metadata": {
        "id": "getchPqDx8Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importaciones"
      ],
      "metadata": {
        "id": "99R2gLcMyCPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import torch\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "DaJoFoOtx8v8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1590c9-5323-4d01-891a-06c90eef007a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a6d56d193f0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el masker y explainer\n",
        "masker = shap.maskers.Text(tokenizer=pipe.tokenizer)\n",
        "explainer = shap.Explainer(pipe, masker)\n",
        "\n",
        "# Aseguramos textos, convertimos a string y limitamos a 1000 caracteres (preparamos los cinco primeros registros)\n",
        "sample_texts_shap = df['Text'].dropna().astype(str).apply(lambda x: x[:1000]).tolist()[:5]\n",
        "\n",
        "# Obtener explicaciones\n",
        "shap_values = explainer(sample_texts_shap)"
      ],
      "metadata": {
        "id": "TF8t8eDRZAt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar una explicación\n",
        "shap.plots.text(shap_values[0], display=True)"
      ],
      "metadata": {
        "id": "YEkJK3itNHvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la explicación SHAP como archivo HTML"
      ],
      "metadata": {
        "id": "WaTaQnnEpU8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar como archivo HTML\n",
        "html_explanation = shap.plots.text(shap_values[0], display=False)\n",
        "with open(\"shap_explicacion_BETO.html\", \"w\", encoding=\"utf-8\") as f:f.write(html_explanation)"
      ],
      "metadata": {
        "id": "rGqOh8R-pXhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de barras Tokens más influyentes (sin filtrar)"
      ],
      "metadata": {
        "id": "fzAUa69d43gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener tokens y valores SHAP para la clase 1 (\"fake\")\n",
        "tokens = shap_values[0].data\n",
        "importancias = shap_values[0].values[:, 1]  # Tomamos la importancia para la clase 1\n",
        "\n",
        "# Crear DataFrame\n",
        "df_orden = pd.DataFrame({\"Token\": tokens, \"SHAP\": importancias})\n",
        "\n",
        "# Seleccionar top 50 por magnitud del SHAP value\n",
        "df_orden['SHAP_abs'] = df_orden['SHAP'].abs()\n",
        "df_orden = df_orden.sort_values(by='SHAP_abs', ascending=False).head(50)\n",
        "\n",
        "# Ordenar por magnitud absoluta (impacto)\n",
        "df_orden[\"SHAP_abs\"] = df_orden[\"SHAP\"].abs()\n",
        "df_ordenado = df_orden.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "# Seleccionar top 50 tokens más influyentes\n",
        "top_n = 50\n",
        "df_top = df_ordenado.head(top_n)\n",
        "\n",
        "# Crear gráfico de barras\n",
        "plt.figure(figsize=(16, 6))\n",
        "bars = plt.bar(df_top[\"Token\"], df_top[\"SHAP\"], edgecolor='black')\n",
        "\n",
        "# Colorear según signo\n",
        "for bar, value in zip(bars, df_top[\"SHAP\"]):\n",
        "    bar.set_color('#1f77b4' if value > 0 else 'red')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Importancia atribuida por BETO (clase: fake) — filtrado\")\n",
        "plt.xlabel(\"Token\")\n",
        "plt.ylabel(\"Puntuación de importancia\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVWqWedvSi6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de barras importancia FILTRADO"
      ],
      "metadata": {
        "id": "DV0uriHWtzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descargar stopwords\n",
        "nltk.download('stopwords')\n",
        "spanish_stopwords = set(stopwords.words('spanish'))\n",
        "\n",
        "# Obtener tokens y valores SHAP para la clase 1 (\"fake\")\n",
        "tokens = [t.strip() for t in shap_values[0].data]  # Limpieza: eliminar espacios extra\n",
        "importancias = shap_values[0].values[:, 1]  # Importancia para clase 1\n",
        "\n",
        "# Crear DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Token\": tokens,\n",
        "    \"SHAP\": importancias\n",
        "})\n",
        "\n",
        "# Filtrar:\n",
        "df_filtrado = df[df[\"Token\"].str.isalpha()]  # 1. Eliminar tokens que no son alfabéticos\n",
        "df_filtrado = df_filtrado[~df_filtrado[\"Token\"].str.lower().isin(spanish_stopwords)]  # 2. Eliminar stopwords\n",
        "df_filtrado = df_filtrado[df_filtrado[\"Token\"].str.len() >= 4]  # 3. Eliminar tokens con menos de 4 letras\n",
        "\n",
        "# Ordenar por magnitud absoluta (impacto)\n",
        "df_filtrado[\"SHAP_abs\"] = df_filtrado[\"SHAP\"].abs()\n",
        "df_sorted = df_filtrado.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "# Seleccionar top 50 tokens más influyentes\n",
        "top_n = 50\n",
        "df_top = df_sorted.head(top_n)\n",
        "\n",
        "# Crear gráfico de barras\n",
        "plt.figure(figsize=(16, 6))\n",
        "bars = plt.bar(df_top[\"Token\"], df_top[\"SHAP\"], edgecolor='black')\n",
        "\n",
        "# Colorear según signo\n",
        "for bar, value in zip(bars, df_top[\"SHAP\"]):\n",
        "    bar.set_color('#1f77b4' if value > 0 else 'red')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Importancia atribuida por BETO (clase: fake) — filtrado\")\n",
        "plt.xlabel(\"Token\")\n",
        "plt.ylabel(\"Puntuación de importancia\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rkrgjISAtAs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras"
      ],
      "metadata": {
        "id": "ddjsjMW-dRhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Crear diccionario de frecuencias\n",
        "frequencies = dict(zip(df_top[\"Token\"], df_top[\"SHAP_abs\"]))\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# Función de color aleatorio\n",
        "def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
        "    return \"hsl({}, 100%, 40%)\".format(random.randint(0, 360))\n",
        "\n",
        "# Crear y generar la nube\n",
        "wc = WordCloud(width=800, height=400, background_color='white', color_func=random_color_func)\n",
        "wc.generate_from_frequencies(frequencies)\n",
        "\n",
        "# Mostrar nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Nube de palabras SHAP\\n\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SfXARdmsboGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokens más influyentes FILTRADO (con valores exactos)"
      ],
      "metadata": {
        "id": "WPewUXFmsqs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_shap_explicacion2(shap_value, top_n=5, filtrar=True, class_index=None):\n",
        "\n",
        "    # 1. Qué clase usar\n",
        "    base_values = shap_value.base_values\n",
        "    class_index = 1\n",
        "\n",
        "    base_value = base_values[class_index] if isinstance(base_values, np.ndarray) else base_values\n",
        "\n",
        "    # 2. Extraer valores SHAP de la clase activa\n",
        "    shap_vals = shap_value.values\n",
        "    if isinstance(shap_vals[0], np.ndarray):\n",
        "        shap_vals = [v[class_index] for v in shap_vals]\n",
        "\n",
        "    tokens = [t.strip() for t in shap_value.data]  # Eliminamos espacios extra\n",
        "    total_contrib = np.sum(shap_vals)\n",
        "    fx = base_value + total_contrib\n",
        "\n",
        "    print(\"Análisis de predicción individual\")\n",
        "    print(f\"Clase analizada: {class_index}\")\n",
        "    print(f\"Valor base del modelo: {base_value:.3f}\")\n",
        "    print(f\"Suma total de contribuciones (tokens): {total_contrib:.3f}\")\n",
        "    print(f\"Predicción final (f(x)) ≈ {fx:.3f}\")\n",
        "\n",
        "    # 3. Crear DataFrame de tokens\n",
        "    df = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"SHAP\": shap_vals\n",
        "    })\n",
        "\n",
        "    # 4. Filtro\n",
        "    if filtrar:\n",
        "        df[\"Token\"] = df[\"Token\"].str.strip()  # limpieza adicional por seguridad\n",
        "        df = df[df[\"Token\"].str.isalpha()]  # Elimina puntuación y símbolos\n",
        "        df = df[~df[\"Token\"].str.lower().isin(spanish_stopwords)]  # Elimina stopwords\n",
        "        df = df[df[\"Token\"].str.len() >= 4]  # Elimina tokens muy cortos\n",
        "\n",
        "    # 5. Ordenar por impacto absoluto\n",
        "    df[\"SHAP_abs\"] = df[\"SHAP\"].abs()\n",
        "    df_sorted = df.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "    # 6. Mostrar top_n tokens más influyentes\n",
        "    top_tokens = df_sorted.head(top_n)\n",
        "\n",
        "    print(\"\\n Tokens más influyentes (positivo o negativo):\")\n",
        "    print(top_tokens[[\"Token\", \"SHAP\"]].to_string(index=False))\n",
        "\n",
        "    # 7. Conclusión\n",
        "    if fx > 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es FALSA (LABEL_1).\"\n",
        "    elif fx < 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es VERDADERA (LABEL_0).\"\n",
        "    else:\n",
        "        conclusion = \"El modelo está indeciso entre FALSA y VERDADERA.\"\n",
        "\n",
        "    print(f\"\\nConclusión del modelo: {conclusion}\")"
      ],
      "metadata": {
        "id": "eyLQW89AviSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analizar_shap_explicacion2(shap_values[0], top_n=10, filtrar=True, class_index=0)"
      ],
      "metadata": {
        "id": "62VJMf4Cluek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de predicción individual (tokens que empujan hacia cada clase)"
      ],
      "metadata": {
        "id": "OxjUcmDr3sap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_shap_explicacion(shap_value, top_n=5, filtrar=True):\n",
        "\n",
        "    # 1. Qué clase usar\n",
        "    base_values = shap_value.base_values\n",
        "    class_index = 1\n",
        "\n",
        "    base_value = base_values[class_index] if isinstance(base_values, np.ndarray) else base_values\n",
        "\n",
        "    # 2. Extraer valores SHAP de la clase activa\n",
        "    shap_vals = shap_value.values\n",
        "    if isinstance(shap_vals[0], np.ndarray):\n",
        "        shap_vals = [v[class_index] for v in shap_vals]\n",
        "\n",
        "    tokens = [t.strip() for t in shap_value.data]  # Eliminamos espacios extra\n",
        "    total_contrib = np.sum(shap_vals)\n",
        "    fx = base_value + total_contrib\n",
        "\n",
        "    print(\"Análisis de predicción individual\")\n",
        "    print(f\"Clase analizada: {class_index}\")\n",
        "    print(f\"Valor base del modelo: {base_value:.3f}\")\n",
        "    print(f\"Suma total de contribuciones (tokens): {total_contrib:.3f}\")\n",
        "    print(f\"Predicción final (f(x)) ≈ {fx:.3f}\")\n",
        "\n",
        "    # 3. Crear DataFrame de tokens\n",
        "    df = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"SHAP\": shap_vals\n",
        "    })\n",
        "\n",
        "    # 4. Filtro\n",
        "    if filtrar:\n",
        "        df[\"Token\"] = df[\"Token\"].str.strip()  # limpieza adicional por seguridad\n",
        "        df = df[df[\"Token\"].str.isalpha()]  # Elimina puntuación y símbolos\n",
        "        df = df[~df[\"Token\"].str.lower().isin(spanish_stopwords)]  # Elimina stopwords\n",
        "        df = df[df[\"Token\"].str.len() >= 4]  # Elimina tokens muy cortos\n",
        "\n",
        "\n",
        "    # 5. Tokens más influyentes\n",
        "    top_neg = df.sort_values(by=\"SHAP\").head(top_n)\n",
        "    top_pos = df.sort_values(by=\"SHAP\", ascending=False).head(top_n)\n",
        "\n",
        "    print(\"\\n🔻 Tokens que empujan hacia la clase contraria:\")\n",
        "    print(top_neg.to_string(index=False))\n",
        "\n",
        "    print(\"\\n🔺 Tokens que empujan hacia esta clase:\")\n",
        "    print(top_pos.to_string(index=False))\n",
        "\n",
        "    # 6. Resultado\n",
        "    if fx > 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es FALSA (LABEL_1).\"\n",
        "    elif fx < 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es VERDADERA (LABEL_0).\"\n",
        "    else:\n",
        "        conclusion = \"El modelo está indeciso entre FALSA y VERDADERA.\"\n",
        "\n",
        "    print(f\"\\nConclusión del modelo: {conclusion}\")"
      ],
      "metadata": {
        "id": "nRexYxu83ssD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analizar_shap_explicacion(shap_values[0])"
      ],
      "metadata": {
        "id": "illRUIzC3skC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tokens más influyentes: análisis global (sobre 100 registros aleatorios)"
      ],
      "metadata": {
        "id": "EevqSCoAwvEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el dataset original con los textos\n",
        "textos = df_texto['text'].dropna().astype(str).apply(lambda x: x[:1000]).tolist()\n",
        "\n",
        "# Seleccionamos una muestra aleatoria\n",
        "sample_texts = random.sample(textos, 100)\n",
        "\n",
        "# Creamos el masker y el explainer si aún no están\n",
        "masker = shap.maskers.Text(tokenizer=pipe.tokenizer)\n",
        "explainer = shap.Explainer(pipe, masker)\n",
        "\n",
        "# Aplicamos SHAP\n",
        "shap_values = explainer(sample_texts)"
      ],
      "metadata": {
        "id": "Lbc6a3G_yv--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar los tokens más influyentes en gráfico de barras"
      ],
      "metadata": {
        "id": "ABwpIYi7wzIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Acumulamos la contribución absoluta de cada token\n",
        "token_contributions = collections.Counter()\n",
        "\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        token_contributions[str(token)] += sum(abs(v) for v in value)\n",
        "\n",
        "# Extraemos los 20 tokens más influyentes\n",
        "top_tokens = token_contributions.most_common(20)\n",
        "\n",
        "# Preparamos el gráfico\n",
        "tokens, values = zip(*top_tokens)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(tokens[::-1], values[::-1])  # De menor a mayor\n",
        "plt.xlabel(\"Importancia total (|SHAP|)\")\n",
        "plt.title(\"Tokens más influyentes según SHAP\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MYIJx4rTw18I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminar stopwords en español"
      ],
      "metadata": {
        "id": "27I3Qq_Jw5DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def limpiar_token(token):\n",
        "    # Elimina todo lo que no sea letra (incluso espacios y signos) y pone en minúsculas\n",
        "    return re.sub(r'[^a-zA-ZáéíóúñÁÉÍÓÚÑ]', '', token.lower().strip())\n",
        "\n",
        "\n",
        "# Calcular contribuciones acumuladas\n",
        "token_contributions = collections.Counter()\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        token_contributions[str(token)] += sum(abs(v) for v in value)\n",
        "\n",
        "# Filtrar: sin stopwords, sin símbolos, mínimo 4 letras\n",
        "token_contributions_filtered = {\n",
        "    token: score for token, score in token_contributions.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "# Obtener los 20 tokens más influyentes\n",
        "top_tokens = sorted(token_contributions_filtered.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens, scores = zip(*top_tokens)\n",
        "\n",
        "# Mostrar gráfico\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens[::-1], scores[::-1])\n",
        "plt.title(\"Tokens más influyentes sin stopwords (BETO - SHAP)\")\n",
        "plt.xlabel(\"Importancia acumulada (|SHAP|)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3rFHL-q7w5zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras"
      ],
      "metadata": {
        "id": "QaNAZijsdNzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar top 20 tokens más influyentes\n",
        "top_n = 20\n",
        "top_tokens = sorted(token_contributions_filtered.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "# Crear diccionario {token: valor absoluto de SHAP}\n",
        "word_weights = {token: score for token, score in top_tokens}\n",
        "\n",
        "# Función de color aleatorio en escala HSL\n",
        "def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
        "    return \"hsl({}, 100%, 40%)\".format(random.randint(0, 360))\n",
        "\n",
        "# Crear y generar la nube de palabras\n",
        "wc = WordCloud(\n",
        "    width=1000,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    color_func=random_color_func,\n",
        "    max_words=top_n\n",
        ")\n",
        "\n",
        "wc.generate_from_frequencies(word_weights)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de palabras (importancia SHAP)\\n\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9SrgYKXDdMiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráficos por clase (tokens que empujan hacia Fake y tokens que empujan hacia True)"
      ],
      "metadata": {
        "id": "uqmvwpeeV7lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contador para contribuciones hacia clase True (0) y clase False (1)\n",
        "contrib_true = collections.Counter()\n",
        "contrib_false = collections.Counter()\n",
        "\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        contrib_true[str(token)] += value[0]   # Clase True\n",
        "        contrib_false[str(token)] += value[1]  # Clase False\n",
        "\n",
        "# Limpieza de tokens\n",
        "contrib_true_cleaned = {\n",
        "    token: score for token, score in contrib_true.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "contrib_false_cleaned = {\n",
        "    token: score for token, score in contrib_false.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "# Mostrar tokens que más empujan hacia clase True\n",
        "top_true = sorted(contrib_true_cleaned.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens_true, scores_true = zip(*top_true)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens_true[::-1], scores_true[::-1])\n",
        "plt.title(\"Tokens que más contribuyen a clase True\")\n",
        "plt.xlabel(\"SHAP (acumulado)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar tokens que más empujan hacia clase False\n",
        "top_false = sorted(contrib_false_cleaned.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens_false, scores_false = zip(*top_false)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens_false[::-1], scores_false[::-1])\n",
        "plt.title(\"\\nTokens que más contribuyen a clase False\")\n",
        "plt.xlabel(\"SHAP (acumulado)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rooa9vQELGA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras bicolor (azul clase 0 - rojo clase 1)"
      ],
      "metadata": {
        "id": "-9eHspdBd6US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir diccionario combinado para la nube (valores absolutos)\n",
        "word_freqs = {}\n",
        "\n",
        "for token, score in top_true:\n",
        "    word_freqs[token] = abs(score)\n",
        "\n",
        "for token, score in top_false:\n",
        "    word_freqs[token] = abs(score)\n",
        "\n",
        "# Crear diccionario de colores: azul para True, rojo para False\n",
        "def color_func(word, *args, **kwargs):\n",
        "    if word in dict(top_true):\n",
        "        return \"blue\"\n",
        "    elif word in dict(top_false):\n",
        "        return \"red\"\n",
        "    else:\n",
        "        return \"gray\"  # fallback por si acaso\n",
        "\n",
        "# Generar nube de palabras\n",
        "wc = WordCloud(\n",
        "    width=1000,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    color_func=color_func\n",
        ")\n",
        "\n",
        "wc.generate_from_frequencies(word_freqs)\n",
        "\n",
        "# Mostrar nube\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Tokens más influyentes según dirección de la predicción (azul = True, rojo = False)\\n\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D2WSlPFBd3rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3LyVwo4nNfLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción manual con noticia nueva\n"
      ],
      "metadata": {
        "id": "mquj8spmzihU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PREDICCIÓN MANUAL CON NOTICIA NUEVA ===\n",
        "\n",
        "\n",
        "# Cargar modelo entrenado desde carpeta local\n",
        "model_path = \"./modelo_beto_fake_news\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Pasar a modo evaluación\n",
        "model.eval()\n",
        "\n",
        "# Noticia de prueba\n",
        "text = \"Una nueva ley establece que todos los coches deberán ser eléctricos en 2035.\"\n",
        "\n",
        "# Tokenizar\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Predicción\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "# Interpretar resultado\n",
        "etiquetas = [\"Real\", \"Fake\"]  # Adjusted labels to match expected output\n",
        "print(\"Predicción:\", etiquetas[predicted_class_id]) # Adjusted labels to match expected output"
      ],
      "metadata": {
        "id": "yid1uS3Gyv8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgswD-a8yv2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# También se puede hacer predicción manual iterando sobre los ejemplos uno a uno"
      ],
      "metadata": {
        "id": "iShYrCtqzwz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from tqdm import tqdm  # Para barra de progreso\n",
        "\n",
        "# Nos aseguramos de que el modelo y tokenizer están cargados\n",
        "model.eval()\n",
        "\n",
        "# Listas para almacenar predicciones y etiquetas reales\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for text, label in tqdm(zip(test_df[\"text\"], test_df[\"label\"]), total=len(test_df)):\n",
        "    # Tokenizar\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    y_true.append(label)\n",
        "    y_pred.append(pred_id)\n",
        "\n",
        "# === Resultados ===\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"\\nReporte completo:\\n\", classification_report(y_true, y_pred, target_names=[\"Fake\", \"Real\"]))"
      ],
      "metadata": {
        "id": "SAE4HFEwyvz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h9ydSIyDNiRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código para la interfaz interactiva"
      ],
      "metadata": {
        "id": "nSqDhdXp0GgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "kucTzmF0x8dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "# Asegúrate de que el modelo y tokenizer están cargados\n",
        "model.eval()\n",
        "etiquetas = [\"Real\", \"Fake\"]\n",
        "\n",
        "def clasificar_noticia(texto):\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = torch.argmax(logits, dim=1).item()\n",
        "    return f\"Predicción: {etiquetas[pred_id]}\"\n",
        "\n",
        "# Interfaz con Gradio\n",
        "demo = gr.Interface(\n",
        "    fn=clasificar_noticia,\n",
        "    inputs=gr.Textbox(lines=6, placeholder=\"Escribe o pega aquí una noticia...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Detector de Noticias Fake con BETO\",\n",
        "    description=\"Introduce una noticia y el modelo clasificará si es FAKE o REAL.\"\n",
        ")\n",
        "\n",
        "# Lanza la app\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "RL4IefNcz6-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}