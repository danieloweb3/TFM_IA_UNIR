{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEMorkUQqRFK"
      },
      "source": [
        "# Carga y an√°lisis del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v31cGuq4LTyf"
      },
      "source": [
        "Instalar librer√≠as necesarias (si no est√°n instaladas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtyEB6awnhMg"
      },
      "outputs": [],
      "source": [
        "!pip install pandas openpyxl matplotlib seaborn --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install numpy==1.26.4 --quiet # (versi√≥n anterior)\n",
        "\n",
        "# Despu√©s de ejecutar estos comandos es necesario reiniciar el kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy-2w2cNLbAe"
      },
      "source": [
        "Importar librer√≠as\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wuw1WylvnkVr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "from datasets import Dataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpqlA2f2Liz3"
      },
      "source": [
        "Carga del dataset y normalizaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14Nmc6yPnoQr"
      },
      "outputs": [],
      "source": [
        "ruta = \"/content/Dataset_Completo.xlsx\"\n",
        "df = pd.read_excel(ruta)\n",
        "\n",
        "# Limpieza y normalizaci√≥n de la columna 'Category'\n",
        "df['Category'] = df['Category'].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Mapeo de etiquetas: 'true' ‚Üí 0 y 'fake' ‚Üí 1\n",
        "df['label'] = df['Category'].map({'true': 0, 'fake': 1})\n",
        "\n",
        "# Verificaci√≥n\n",
        "print(\"Valores √∫nicos en 'Category':\", df['Category'].unique())\n",
        "print(\"Valores √∫nicos en 'label':\", df['label'].unique())\n",
        "print(\"\\nDistribuci√≥n de clases:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuci√≥n de clases"
      ],
      "metadata": {
        "id": "PoRAEZ-PfcTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(data=df, x='label')\n",
        "plt.title(\"Distribuci√≥n de clases (0 = verdadera, 1 = falsa)\")\n",
        "plt.xlabel(\"Etiqueta\")\n",
        "plt.ylabel(\"N√∫mero de ejemplos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6bFaWmWQfB8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos a texto y calculamos la longitud"
      ],
      "metadata": {
        "id": "nPve3OrvfFiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = df['Text'].astype(str).apply(len)\n",
        "print(\"\\nLongitud media de los textos:\", df['text_len'].mean())"
      ],
      "metadata": {
        "id": "kTFMom16fB_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gr√°fico distribuci√≥n de la longitud de los textos"
      ],
      "metadata": {
        "id": "HKnPK89pfgfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['text_len'], bins=40, kde=True)\n",
        "plt.title(\"Distribuci√≥n de la longitud de los textos\")\n",
        "plt.xlabel(\"N√∫mero de caracteres\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFGUF2fFfB6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar primeros registros del dataset"
      ],
      "metadata": {
        "id": "I_VzxflAMsat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los primeros registros del dataset\n",
        "print(\"\\nPrimeros registros del dataset:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IfZyu8-RMq--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos nulos y datos faltantes"
      ],
      "metadata": {
        "id": "QossfHVTMaGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar si existen registros con al menos un campo en blanco o nulo\n",
        "registros_con_faltantes = df[df.isnull().any(axis=1)]\n",
        "total_con_faltantes = registros_con_faltantes.shape[0]\n",
        "\n",
        "# Mostrar resultado general\n",
        "print(f\"¬øExisten registros con datos faltantes?: {total_con_faltantes > 0}\")\n",
        "print(f\"Total de registros con al menos un campo en blanco: {total_con_faltantes}\\n\")\n",
        "\n",
        "# Mostrar el n√∫mero de valores nulos por columna\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "IV1m5_R2fBsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar los primeros registros con campos faltantes\n",
        "if total_con_faltantes > 0:\n",
        "    print(\"\\nPrimeros registros con campos faltantes:\")\n",
        "    print(registros_con_faltantes.head())"
      ],
      "metadata": {
        "id": "6J0zC0XnN8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCo-2vGeL9sv"
      },
      "source": [
        "# Entrenamiento de BETO con el texto completo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Usamos 'text', 'topic', 'source' y 'headline' como entrada. El campo LINK no lo utilizamos para el entrenamiento\n",
        "df_texto = df[['Text', 'Topic', 'Source', 'Headline', 'label']].dropna().copy()\n",
        "\n",
        "# Renombramos todas las columnas\n",
        "df_texto.rename(columns={\n",
        "    'Text': 'text',\n",
        "    'Topic': 'topic',\n",
        "    'Source': 'source',\n",
        "    'Headline': 'headline'\n",
        "}, inplace=True)\n",
        "\n",
        "# 2. Divisi√≥n del dataset en entrenamiento y prueba\n",
        "train_df, test_df = train_test_split(df_texto, test_size=0.2, stratify=df_texto['label'], random_state=42)\n",
        "\n",
        "# 3. Conversi√≥n a datasets de Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# 4. Tokenizador y tokenizaci√≥n\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# 5. Formateo\n",
        "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# 6. Modelo BETO\n",
        "model = BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=2)\n",
        "\n",
        "# 7. Configuraci√≥n de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_texto_completo\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    eval_strategy=\"epoch\",  # Para evaluar cada √©poca\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 8 Preparaci√≥n metricas entrenamiento\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# 9. Entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],  # Espera 2 √©pocas sin mejorar\n",
        ")\n",
        "\n",
        "# 10. Entrenar el modelo\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "G8cal9IfgDsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo entrenado con textos (lo usaremos con LIME)."
      ],
      "metadata": {
        "id": "QzWlJm0woTB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar modelo y tokenizer tras el entrenamiento\n",
        "trainer.save_model(\"./modelo_beto_fake_news\")\n",
        "tokenizer.save_pretrained(\"./modelo_beto_fake_news\")"
      ],
      "metadata": {
        "id": "vAwvbXAqoOjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluaci√≥n del modelo con texto completo"
      ],
      "metadata": {
        "id": "CR7-ETCKgdaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "\n",
        "# 1. Obtener predicciones\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# 2. M√©tricas principales\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "precision = precision_score(labels, preds)\n",
        "recall = recall_score(labels, preds)\n",
        "f1 = f1_score(labels, preds)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# 3. Reporte completo por clase\n",
        "print(\"\\nReporte completo:\")\n",
        "print(classification_report(labels, preds, target_names=[\"True\", \"Fake\"]))\n",
        "\n",
        "# 4. Matriz de confusi√≥n\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"True\", \"Fake\"], yticklabels=[\"True\", \"Fake\"])\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusi√≥n - Texto completo (BETO)')\n",
        "plt.show()\n",
        "\n",
        "# 5. Curva ROC y AUC\n",
        "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "auc = roc_auc_score(labels, probs)\n",
        "fpr, tpr, _ = roc_curve(labels, probs)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Clasificador aleatorio')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('Curva ROC - Modelo con texto completo (BETO)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OouagLS1gDoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Qyt9CJQLM-Im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretabilidad con LIME"
      ],
      "metadata": {
        "id": "ceLPCWBDvXdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar LIME"
      ],
      "metadata": {
        "id": "JSM04IWqvc3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime --quiet"
      ],
      "metadata": {
        "id": "QSZUuz1TvU56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./modelo_beto_fake_news\",\n",
        "    tokenizer=\"./modelo_beto_fake_news\",\n",
        "    return_all_scores=True\n",
        ")"
      ],
      "metadata": {
        "id": "EdqCIQHNX-za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importaciones y funci√≥n predictiva"
      ],
      "metadata": {
        "id": "XxbeTpqOvjbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Definimos los nombres de las clases\n",
        "class_names = ['True', 'Fake']\n",
        "\n",
        "# Funci√≥n para LIME: devuelve solo las probabilidades de clase\n",
        "def predict_lime(texts):\n",
        "    outputs = pipe(texts)\n",
        "    return np.array([[s['score'] for s in o] for o in outputs])"
      ],
      "metadata": {
        "id": "gxU969whvU3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializar el explicador y elegir un texto"
      ],
      "metadata": {
        "id": "mQ5rnlBuvq7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = LimeTextExplainer(class_names=class_names, random_state=42)\n",
        "\n",
        "# Seleccionamos un texto del dataset\n",
        "texto_ejemplo = df['Text'].dropna().astype(str).iloc[0][:1000]  # truncado por seguridad"
      ],
      "metadata": {
        "id": "17v2SWS7vU1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar la explicaci√≥n y visualizarla"
      ],
      "metadata": {
        "id": "oeQeEGCPvtZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(texto_ejemplo, predict_lime, num_features=10)\n",
        "\n",
        "# Mostrar en notebook\n",
        "exp.show_in_notebook(text=True)"
      ],
      "metadata": {
        "id": "Kn3I6n1KvUzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la explicaci√≥n LIME como archivo HTML"
      ],
      "metadata": {
        "id": "eCgcbYQYwoBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar la explicaci√≥n como archivo HTML\n",
        "exp.save_to_file('lime_explicacion_BETO.html')"
      ],
      "metadata": {
        "id": "w-KPAiUsvUxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WO8y-IeRNUdr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjZKGmnywVP5"
      },
      "source": [
        "# Interpretabilidad con SHAP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque las explicaciones SHAP se generan sobre un modelo base multiling√ºe, la interpretaci√≥n general puede extrapolarse razonablemente al comportamiento del modelo fine-tuned entrenado en este trabajo, ya que ambos comparten la misma arquitectura."
      ],
      "metadata": {
        "id": "K-MhN4Xqzptn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar librer√≠as necesarias"
      ],
      "metadata": {
        "id": "Djmvjn_wx7rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap scikit-learn nltk --quiet"
      ],
      "metadata": {
        "id": "getchPqDx8Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importaciones"
      ],
      "metadata": {
        "id": "99R2gLcMyCPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import torch\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "DaJoFoOtx8v8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1590c9-5323-4d01-891a-06c90eef007a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a6d56d193f0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el masker y explainer\n",
        "masker = shap.maskers.Text(tokenizer=pipe.tokenizer)\n",
        "explainer = shap.Explainer(pipe, masker)\n",
        "\n",
        "# Aseguramos textos, convertimos a string y limitamos a 1000 caracteres (preparamos los cinco primeros registros)\n",
        "sample_texts_shap = df['Text'].dropna().astype(str).apply(lambda x: x[:1000]).tolist()[:5]\n",
        "\n",
        "# Obtener explicaciones\n",
        "shap_values = explainer(sample_texts_shap)"
      ],
      "metadata": {
        "id": "TF8t8eDRZAt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar una explicaci√≥n\n",
        "shap.plots.text(shap_values[0], display=True)"
      ],
      "metadata": {
        "id": "YEkJK3itNHvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la explicaci√≥n SHAP como archivo HTML"
      ],
      "metadata": {
        "id": "WaTaQnnEpU8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar como archivo HTML\n",
        "html_explanation = shap.plots.text(shap_values[0], display=False)\n",
        "with open(\"shap_explicacion_BETO.html\", \"w\", encoding=\"utf-8\") as f:f.write(html_explanation)"
      ],
      "metadata": {
        "id": "rGqOh8R-pXhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gr√°fico de barras Tokens m√°s influyentes (sin filtrar)"
      ],
      "metadata": {
        "id": "fzAUa69d43gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener tokens y valores SHAP para la clase 1 (\"fake\")\n",
        "tokens = shap_values[0].data\n",
        "importancias = shap_values[0].values[:, 1]  # Tomamos la importancia para la clase 1\n",
        "\n",
        "# Crear DataFrame\n",
        "df_orden = pd.DataFrame({\"Token\": tokens, \"SHAP\": importancias})\n",
        "\n",
        "# Seleccionar top 50 por magnitud del SHAP value\n",
        "df_orden['SHAP_abs'] = df_orden['SHAP'].abs()\n",
        "df_orden = df_orden.sort_values(by='SHAP_abs', ascending=False).head(50)\n",
        "\n",
        "# Ordenar por magnitud absoluta (impacto)\n",
        "df_orden[\"SHAP_abs\"] = df_orden[\"SHAP\"].abs()\n",
        "df_ordenado = df_orden.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "# Seleccionar top 50 tokens m√°s influyentes\n",
        "top_n = 50\n",
        "df_top = df_ordenado.head(top_n)\n",
        "\n",
        "# Crear gr√°fico de barras\n",
        "plt.figure(figsize=(16, 6))\n",
        "bars = plt.bar(df_top[\"Token\"], df_top[\"SHAP\"], edgecolor='black')\n",
        "\n",
        "# Colorear seg√∫n signo\n",
        "for bar, value in zip(bars, df_top[\"SHAP\"]):\n",
        "    bar.set_color('#1f77b4' if value > 0 else 'red')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Importancia atribuida por BETO (clase: fake) ‚Äî filtrado\")\n",
        "plt.xlabel(\"Token\")\n",
        "plt.ylabel(\"Puntuaci√≥n de importancia\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVWqWedvSi6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gr√°fico de barras importancia FILTRADO"
      ],
      "metadata": {
        "id": "DV0uriHWtzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descargar stopwords\n",
        "nltk.download('stopwords')\n",
        "spanish_stopwords = set(stopwords.words('spanish'))\n",
        "\n",
        "# Obtener tokens y valores SHAP para la clase 1 (\"fake\")\n",
        "tokens = [t.strip() for t in shap_values[0].data]  # Limpieza: eliminar espacios extra\n",
        "importancias = shap_values[0].values[:, 1]  # Importancia para clase 1\n",
        "\n",
        "# Crear DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Token\": tokens,\n",
        "    \"SHAP\": importancias\n",
        "})\n",
        "\n",
        "# Filtrar:\n",
        "df_filtrado = df[df[\"Token\"].str.isalpha()]  # 1. Eliminar tokens que no son alfab√©ticos\n",
        "df_filtrado = df_filtrado[~df_filtrado[\"Token\"].str.lower().isin(spanish_stopwords)]  # 2. Eliminar stopwords\n",
        "df_filtrado = df_filtrado[df_filtrado[\"Token\"].str.len() >= 4]  # 3. Eliminar tokens con menos de 4 letras\n",
        "\n",
        "# Ordenar por magnitud absoluta (impacto)\n",
        "df_filtrado[\"SHAP_abs\"] = df_filtrado[\"SHAP\"].abs()\n",
        "df_sorted = df_filtrado.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "# Seleccionar top 50 tokens m√°s influyentes\n",
        "top_n = 50\n",
        "df_top = df_sorted.head(top_n)\n",
        "\n",
        "# Crear gr√°fico de barras\n",
        "plt.figure(figsize=(16, 6))\n",
        "bars = plt.bar(df_top[\"Token\"], df_top[\"SHAP\"], edgecolor='black')\n",
        "\n",
        "# Colorear seg√∫n signo\n",
        "for bar, value in zip(bars, df_top[\"SHAP\"]):\n",
        "    bar.set_color('#1f77b4' if value > 0 else 'red')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Importancia atribuida por BETO (clase: fake) ‚Äî filtrado\")\n",
        "plt.xlabel(\"Token\")\n",
        "plt.ylabel(\"Puntuaci√≥n de importancia\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rkrgjISAtAs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras"
      ],
      "metadata": {
        "id": "ddjsjMW-dRhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Crear diccionario de frecuencias\n",
        "frequencies = dict(zip(df_top[\"Token\"], df_top[\"SHAP_abs\"]))\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# Funci√≥n de color aleatorio\n",
        "def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
        "    return \"hsl({}, 100%, 40%)\".format(random.randint(0, 360))\n",
        "\n",
        "# Crear y generar la nube\n",
        "wc = WordCloud(width=800, height=400, background_color='white', color_func=random_color_func)\n",
        "wc.generate_from_frequencies(frequencies)\n",
        "\n",
        "# Mostrar nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(\"Nube de palabras SHAP\\n\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SfXARdmsboGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokens m√°s influyentes FILTRADO (con valores exactos)"
      ],
      "metadata": {
        "id": "WPewUXFmsqs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_shap_explicacion2(shap_value, top_n=5, filtrar=True, class_index=None):\n",
        "\n",
        "    # 1. Qu√© clase usar\n",
        "    base_values = shap_value.base_values\n",
        "    class_index = 1\n",
        "\n",
        "    base_value = base_values[class_index] if isinstance(base_values, np.ndarray) else base_values\n",
        "\n",
        "    # 2. Extraer valores SHAP de la clase activa\n",
        "    shap_vals = shap_value.values\n",
        "    if isinstance(shap_vals[0], np.ndarray):\n",
        "        shap_vals = [v[class_index] for v in shap_vals]\n",
        "\n",
        "    tokens = [t.strip() for t in shap_value.data]  # Eliminamos espacios extra\n",
        "    total_contrib = np.sum(shap_vals)\n",
        "    fx = base_value + total_contrib\n",
        "\n",
        "    print(\"An√°lisis de predicci√≥n individual\")\n",
        "    print(f\"Clase analizada: {class_index}\")\n",
        "    print(f\"Valor base del modelo: {base_value:.3f}\")\n",
        "    print(f\"Suma total de contribuciones (tokens): {total_contrib:.3f}\")\n",
        "    print(f\"Predicci√≥n final (f(x)) ‚âà {fx:.3f}\")\n",
        "\n",
        "    # 3. Crear DataFrame de tokens\n",
        "    df = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"SHAP\": shap_vals\n",
        "    })\n",
        "\n",
        "    # 4. Filtro\n",
        "    if filtrar:\n",
        "        df[\"Token\"] = df[\"Token\"].str.strip()  # limpieza adicional por seguridad\n",
        "        df = df[df[\"Token\"].str.isalpha()]  # Elimina puntuaci√≥n y s√≠mbolos\n",
        "        df = df[~df[\"Token\"].str.lower().isin(spanish_stopwords)]  # Elimina stopwords\n",
        "        df = df[df[\"Token\"].str.len() >= 4]  # Elimina tokens muy cortos\n",
        "\n",
        "    # 5. Ordenar por impacto absoluto\n",
        "    df[\"SHAP_abs\"] = df[\"SHAP\"].abs()\n",
        "    df_sorted = df.sort_values(by=\"SHAP_abs\", ascending=False)\n",
        "\n",
        "    # 6. Mostrar top_n tokens m√°s influyentes\n",
        "    top_tokens = df_sorted.head(top_n)\n",
        "\n",
        "    print(\"\\n Tokens m√°s influyentes (positivo o negativo):\")\n",
        "    print(top_tokens[[\"Token\", \"SHAP\"]].to_string(index=False))\n",
        "\n",
        "    # 7. Conclusi√≥n\n",
        "    if fx > 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es FALSA (LABEL_1).\"\n",
        "    elif fx < 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es VERDADERA (LABEL_0).\"\n",
        "    else:\n",
        "        conclusion = \"El modelo est√° indeciso entre FALSA y VERDADERA.\"\n",
        "\n",
        "    print(f\"\\nConclusi√≥n del modelo: {conclusion}\")"
      ],
      "metadata": {
        "id": "eyLQW89AviSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analizar_shap_explicacion2(shap_values[0], top_n=10, filtrar=True, class_index=0)"
      ],
      "metadata": {
        "id": "62VJMf4Cluek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lisis de predicci√≥n individual (tokens que empujan hacia cada clase)"
      ],
      "metadata": {
        "id": "OxjUcmDr3sap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analizar_shap_explicacion(shap_value, top_n=5, filtrar=True):\n",
        "\n",
        "    # 1. Qu√© clase usar\n",
        "    base_values = shap_value.base_values\n",
        "    class_index = 1\n",
        "\n",
        "    base_value = base_values[class_index] if isinstance(base_values, np.ndarray) else base_values\n",
        "\n",
        "    # 2. Extraer valores SHAP de la clase activa\n",
        "    shap_vals = shap_value.values\n",
        "    if isinstance(shap_vals[0], np.ndarray):\n",
        "        shap_vals = [v[class_index] for v in shap_vals]\n",
        "\n",
        "    tokens = [t.strip() for t in shap_value.data]  # Eliminamos espacios extra\n",
        "    total_contrib = np.sum(shap_vals)\n",
        "    fx = base_value + total_contrib\n",
        "\n",
        "    print(\"An√°lisis de predicci√≥n individual\")\n",
        "    print(f\"Clase analizada: {class_index}\")\n",
        "    print(f\"Valor base del modelo: {base_value:.3f}\")\n",
        "    print(f\"Suma total de contribuciones (tokens): {total_contrib:.3f}\")\n",
        "    print(f\"Predicci√≥n final (f(x)) ‚âà {fx:.3f}\")\n",
        "\n",
        "    # 3. Crear DataFrame de tokens\n",
        "    df = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"SHAP\": shap_vals\n",
        "    })\n",
        "\n",
        "    # 4. Filtro\n",
        "    if filtrar:\n",
        "        df[\"Token\"] = df[\"Token\"].str.strip()  # limpieza adicional por seguridad\n",
        "        df = df[df[\"Token\"].str.isalpha()]  # Elimina puntuaci√≥n y s√≠mbolos\n",
        "        df = df[~df[\"Token\"].str.lower().isin(spanish_stopwords)]  # Elimina stopwords\n",
        "        df = df[df[\"Token\"].str.len() >= 4]  # Elimina tokens muy cortos\n",
        "\n",
        "\n",
        "    # 5. Tokens m√°s influyentes\n",
        "    top_neg = df.sort_values(by=\"SHAP\").head(top_n)\n",
        "    top_pos = df.sort_values(by=\"SHAP\", ascending=False).head(top_n)\n",
        "\n",
        "    print(\"\\nüîª Tokens que empujan hacia la clase contraria:\")\n",
        "    print(top_neg.to_string(index=False))\n",
        "\n",
        "    print(\"\\nüî∫ Tokens que empujan hacia esta clase:\")\n",
        "    print(top_pos.to_string(index=False))\n",
        "\n",
        "    # 6. Resultado\n",
        "    if fx > 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es FALSA (LABEL_1).\"\n",
        "    elif fx < 0.5:\n",
        "        conclusion = \"El modelo cree que esta noticia es VERDADERA (LABEL_0).\"\n",
        "    else:\n",
        "        conclusion = \"El modelo est√° indeciso entre FALSA y VERDADERA.\"\n",
        "\n",
        "    print(f\"\\nConclusi√≥n del modelo: {conclusion}\")"
      ],
      "metadata": {
        "id": "nRexYxu83ssD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analizar_shap_explicacion(shap_values[0])"
      ],
      "metadata": {
        "id": "illRUIzC3skC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tokens m√°s influyentes: an√°lisis global (sobre 100 registros aleatorios)"
      ],
      "metadata": {
        "id": "EevqSCoAwvEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el dataset original con los textos\n",
        "textos = df_texto['text'].dropna().astype(str).apply(lambda x: x[:1000]).tolist()\n",
        "\n",
        "# Seleccionamos una muestra aleatoria\n",
        "sample_texts = random.sample(textos, 100)\n",
        "\n",
        "# Creamos el masker y el explainer si a√∫n no est√°n\n",
        "masker = shap.maskers.Text(tokenizer=pipe.tokenizer)\n",
        "explainer = shap.Explainer(pipe, masker)\n",
        "\n",
        "# Aplicamos SHAP\n",
        "shap_values = explainer(sample_texts)"
      ],
      "metadata": {
        "id": "Lbc6a3G_yv--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar los tokens m√°s influyentes en gr√°fico de barras"
      ],
      "metadata": {
        "id": "ABwpIYi7wzIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Acumulamos la contribuci√≥n absoluta de cada token\n",
        "token_contributions = collections.Counter()\n",
        "\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        token_contributions[str(token)] += sum(abs(v) for v in value)\n",
        "\n",
        "# Extraemos los 20 tokens m√°s influyentes\n",
        "top_tokens = token_contributions.most_common(20)\n",
        "\n",
        "# Preparamos el gr√°fico\n",
        "tokens, values = zip(*top_tokens)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(tokens[::-1], values[::-1])  # De menor a mayor\n",
        "plt.xlabel(\"Importancia total (|SHAP|)\")\n",
        "plt.title(\"Tokens m√°s influyentes seg√∫n SHAP\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MYIJx4rTw18I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminar stopwords en espa√±ol"
      ],
      "metadata": {
        "id": "27I3Qq_Jw5DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def limpiar_token(token):\n",
        "    # Elimina todo lo que no sea letra (incluso espacios y signos) y pone en min√∫sculas\n",
        "    return re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë]', '', token.lower().strip())\n",
        "\n",
        "\n",
        "# Calcular contribuciones acumuladas\n",
        "token_contributions = collections.Counter()\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        token_contributions[str(token)] += sum(abs(v) for v in value)\n",
        "\n",
        "# Filtrar: sin stopwords, sin s√≠mbolos, m√≠nimo 4 letras\n",
        "token_contributions_filtered = {\n",
        "    token: score for token, score in token_contributions.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "# Obtener los 20 tokens m√°s influyentes\n",
        "top_tokens = sorted(token_contributions_filtered.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens, scores = zip(*top_tokens)\n",
        "\n",
        "# Mostrar gr√°fico\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens[::-1], scores[::-1])\n",
        "plt.title(\"Tokens m√°s influyentes sin stopwords (BETO - SHAP)\")\n",
        "plt.xlabel(\"Importancia acumulada (|SHAP|)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3rFHL-q7w5zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras"
      ],
      "metadata": {
        "id": "QaNAZijsdNzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar top 20 tokens m√°s influyentes\n",
        "top_n = 20\n",
        "top_tokens = sorted(token_contributions_filtered.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "# Crear diccionario {token: valor absoluto de SHAP}\n",
        "word_weights = {token: score for token, score in top_tokens}\n",
        "\n",
        "# Funci√≥n de color aleatorio en escala HSL\n",
        "def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
        "    return \"hsl({}, 100%, 40%)\".format(random.randint(0, 360))\n",
        "\n",
        "# Crear y generar la nube de palabras\n",
        "wc = WordCloud(\n",
        "    width=1000,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    color_func=random_color_func,\n",
        "    max_words=top_n\n",
        ")\n",
        "\n",
        "wc.generate_from_frequencies(word_weights)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de palabras (importancia SHAP)\\n\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9SrgYKXDdMiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gr√°ficos por clase (tokens que empujan hacia Fake y tokens que empujan hacia True)"
      ],
      "metadata": {
        "id": "uqmvwpeeV7lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contador para contribuciones hacia clase True (0) y clase False (1)\n",
        "contrib_true = collections.Counter()\n",
        "contrib_false = collections.Counter()\n",
        "\n",
        "for sv in shap_values:\n",
        "    for token, value in zip(sv.data, sv.values):\n",
        "        contrib_true[str(token)] += value[0]   # Clase True\n",
        "        contrib_false[str(token)] += value[1]  # Clase False\n",
        "\n",
        "# Limpieza de tokens\n",
        "contrib_true_cleaned = {\n",
        "    token: score for token, score in contrib_true.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "contrib_false_cleaned = {\n",
        "    token: score for token, score in contrib_false.items()\n",
        "    if limpiar_token(token) not in spanish_stopwords and limpiar_token(token).isalpha() and len(limpiar_token(token)) >= 4\n",
        "}\n",
        "\n",
        "# Mostrar tokens que m√°s empujan hacia clase True\n",
        "top_true = sorted(contrib_true_cleaned.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens_true, scores_true = zip(*top_true)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens_true[::-1], scores_true[::-1])\n",
        "plt.title(\"Tokens que m√°s contribuyen a clase True\")\n",
        "plt.xlabel(\"SHAP (acumulado)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar tokens que m√°s empujan hacia clase False\n",
        "top_false = sorted(contrib_false_cleaned.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "tokens_false, scores_false = zip(*top_false)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(tokens_false[::-1], scores_false[::-1])\n",
        "plt.title(\"\\nTokens que m√°s contribuyen a clase False\")\n",
        "plt.xlabel(\"SHAP (acumulado)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rooa9vQELGA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nube de palabras bicolor (azul clase 0 - rojo clase 1)"
      ],
      "metadata": {
        "id": "-9eHspdBd6US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir diccionario combinado para la nube (valores absolutos)\n",
        "word_freqs = {}\n",
        "\n",
        "for token, score in top_true:\n",
        "    word_freqs[token] = abs(score)\n",
        "\n",
        "for token, score in top_false:\n",
        "    word_freqs[token] = abs(score)\n",
        "\n",
        "# Crear diccionario de colores: azul para True, rojo para False\n",
        "def color_func(word, *args, **kwargs):\n",
        "    if word in dict(top_true):\n",
        "        return \"blue\"\n",
        "    elif word in dict(top_false):\n",
        "        return \"red\"\n",
        "    else:\n",
        "        return \"gray\"  # fallback por si acaso\n",
        "\n",
        "# Generar nube de palabras\n",
        "wc = WordCloud(\n",
        "    width=1000,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    color_func=color_func\n",
        ")\n",
        "\n",
        "wc.generate_from_frequencies(word_freqs)\n",
        "\n",
        "# Mostrar nube\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Tokens m√°s influyentes seg√∫n direcci√≥n de la predicci√≥n (azul = True, rojo = False)\\n\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D2WSlPFBd3rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3LyVwo4nNfLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicci√≥n manual con noticia nueva\n"
      ],
      "metadata": {
        "id": "mquj8spmzihU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PREDICCI√ìN MANUAL CON NOTICIA NUEVA ===\n",
        "\n",
        "\n",
        "# Cargar modelo entrenado desde carpeta local\n",
        "model_path = \"./modelo_beto_fake_news\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Pasar a modo evaluaci√≥n\n",
        "model.eval()\n",
        "\n",
        "# Noticia de prueba\n",
        "text = \"Una nueva ley establece que todos los coches deber√°n ser el√©ctricos en 2035.\"\n",
        "\n",
        "# Tokenizar\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Predicci√≥n\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "# Interpretar resultado\n",
        "etiquetas = [\"Real\", \"Fake\"]  # Adjusted labels to match expected output\n",
        "print(\"Predicci√≥n:\", etiquetas[predicted_class_id]) # Adjusted labels to match expected output"
      ],
      "metadata": {
        "id": "yid1uS3Gyv8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgswD-a8yv2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tambi√©n se puede hacer predicci√≥n manual iterando sobre los ejemplos uno a uno"
      ],
      "metadata": {
        "id": "iShYrCtqzwz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from tqdm import tqdm  # Para barra de progreso\n",
        "\n",
        "# Nos aseguramos de que el modelo y tokenizer est√°n cargados\n",
        "model.eval()\n",
        "\n",
        "# Listas para almacenar predicciones y etiquetas reales\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for text, label in tqdm(zip(test_df[\"text\"], test_df[\"label\"]), total=len(test_df)):\n",
        "    # Tokenizar\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    y_true.append(label)\n",
        "    y_pred.append(pred_id)\n",
        "\n",
        "# === Resultados ===\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"\\nReporte completo:\\n\", classification_report(y_true, y_pred, target_names=[\"Fake\", \"Real\"]))"
      ],
      "metadata": {
        "id": "SAE4HFEwyvz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "h9ydSIyDNiRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C√≥digo para la interfaz interactiva"
      ],
      "metadata": {
        "id": "nSqDhdXp0GgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "kucTzmF0x8dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "# Aseg√∫rate de que el modelo y tokenizer est√°n cargados\n",
        "model.eval()\n",
        "etiquetas = [\"Real\", \"Fake\"]\n",
        "\n",
        "def clasificar_noticia(texto):\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_id = torch.argmax(logits, dim=1).item()\n",
        "    return f\"Predicci√≥n: {etiquetas[pred_id]}\"\n",
        "\n",
        "# Interfaz con Gradio\n",
        "demo = gr.Interface(\n",
        "    fn=clasificar_noticia,\n",
        "    inputs=gr.Textbox(lines=6, placeholder=\"Escribe o pega aqu√≠ una noticia...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Detector de Noticias Fake con BETO\",\n",
        "    description=\"Introduce una noticia y el modelo clasificar√° si es FAKE o REAL.\"\n",
        ")\n",
        "\n",
        "# Lanza la app\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "RL4IefNcz6-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}